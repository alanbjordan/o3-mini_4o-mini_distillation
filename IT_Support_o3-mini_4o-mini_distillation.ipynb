{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store high-quality outputs of a large model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "if not client.api_key:\n",
    "    raise ValueError(\"API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "user_input = \"\"\"Hi IT support team, I'm having trouble with my work laptop running Windows 10. It frequently freezes and displays a blue screen error with the code \"SYSTEM_SERVICE_EXCEPTION.\" This issue tends to occur when I try to run multiple applications simultaneously, especially when using our project management software. I've already tried restarting the computer and checking for updates, but the problem persists. Can you please assist me in diagnosing and resolving this issue? Thank you!\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model= \"gpt-4o-mini-2024-07-18\",\n",
    "    messages= [\n",
    "    { 'role': \"system\", 'content': \"You are a corporate IT support expert.\" },\n",
    "    { 'role': \"user\", 'content': user_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o3-Mini Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the helper function to generate a diverse user message by calling an LLM\n",
    "def generate_diverse_user_message():\n",
    "    \"\"\"\n",
    "    This function calls the LLM to generate a new question.\n",
    "    The prompt instructs the LLM to assume the role of a new hire at a tech company\n",
    "    who is having trouble with their machine and needs assistance, and then to ask a question.\n",
    "    \"\"\"\n",
    "    generation_prompt = (\n",
    "        \"You are a new hire at a tech company. You are experiencing an issue with your work machine \"\n",
    "        \"and need assistance solving the problem. Please ask a question to the IT support team \"\n",
    "        \"about the issue you are facing. Be specific and provide enough context for them to understand. Just ask the question, \"\n",
    "    )\n",
    "    \n",
    "    # Call the LLM to get a new question based on the prompt\n",
    "    generation_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a creative question generator.\"},\n",
    "            {\"role\": \"user\", \"content\": generation_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Return the newly generated user message\n",
    "    return generation_response.choices[0].message.content\n",
    "\n",
    "# Base system message to provide context for the corporate IT support expert\n",
    "system_message = { \"role\": \"system\", \"content\": \"You are a corporate IT support expert.\" }\n",
    "\n",
    "# Container for storing completions\n",
    "completions = []\n",
    "\n",
    "# Generate 300 completions with diverse user messages\n",
    "for i in range(300):\n",
    "    # Generate a diverse user query for each iteration using the additional LLM call.\n",
    "    diversified_message = generate_diverse_user_message()\n",
    "    \n",
    "    # Create a chat completion using the dynamic user query\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"o3-mini-2025-01-31\",\n",
    "        messages=[\n",
    "            system_message,\n",
    "            { \"role\": \"user\", \"content\": diversified_message }\n",
    "        ],\n",
    "        store=True,\n",
    "        metadata={\n",
    "            \"model\": \"o3-mini-2025-01-31\",\n",
    "            \"system\": \"IT support expert\",\n",
    "            \"user\": \"IT user\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get the generated response and store it\n",
    "    response_text = completion.choices[0].message.content\n",
    "    completions.append(response_text)\n",
    "    \n",
    "    # Print the iteration and the corresponding response from the LLM\n",
    "    print(f\"Completion {i+1}:\\nUser Query: {diversified_message}\\nResponse: {response_text}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o-Mini Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the helper function to generate a diverse user message by calling an LLM\n",
    "def generate_diverse_user_message():\n",
    "    \"\"\"\n",
    "    This function calls the LLM to generate a new question.\n",
    "    The prompt instructs the LLM to assume the role of a new hire at a tech company\n",
    "    who is having trouble with their machine and needs assistance, and then to ask a question.\n",
    "    \"\"\"\n",
    "    generation_prompt = (\n",
    "        \"You are a new hire at a tech company. You are experiencing an issue with your work machine \"\n",
    "        \"and need assistance solving the problem. Please ask a question to the IT support team \"\n",
    "        \"about the issue you are facing. Be specific and provide enough context for them to understand. Just ask the question, \"\n",
    "    )\n",
    "    \n",
    "    # Call the LLM to get a new question based on the prompt\n",
    "    generation_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a creative question generator.\"},\n",
    "            {\"role\": \"user\", \"content\": generation_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Return the newly generated user message\n",
    "    return generation_response.choices[0].message.content\n",
    "\n",
    "# Base system message to provide context for the corporate IT support expert\n",
    "system_message = { \"role\": \"system\", \"content\": \"You are a corporate IT support expert.\" }\n",
    "\n",
    "# Container for storing completions\n",
    "completions = []\n",
    "\n",
    "# Generate 30 completions with diverse user messages\n",
    "for i in range(30):\n",
    "    # Generate a diverse user query for each iteration using the additional LLM call.\n",
    "    diversified_message = generate_diverse_user_message()\n",
    "    \n",
    "    # Create a chat completion using the dynamic user query\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            system_message,\n",
    "            { \"role\": \"user\", \"content\": diversified_message }\n",
    "        ],\n",
    "        store=True,\n",
    "        metadata={\n",
    "            \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "            \"system\": \"IT support expert\",\n",
    "            \"user\": \"IT user\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get the generated response and store it\n",
    "    response_text = completion.choices[0].message.content\n",
    "    completions.append(response_text)\n",
    "    \n",
    "    # Print the iteration and the corresponding response from the LLM\n",
    "    print(f\"Completion {i+1}:\\nUser Query: {diversified_message}\\nResponse: {response_text}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Model Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "user_input = \"\"\"Hi IT support team, I'm having trouble with my work laptop running Windows 10. It frequently freezes and displays a blue screen error with the code \"SYSTEM_SERVICE_EXCEPTION.\" This issue tends to occur when I try to run multiple applications simultaneously, especially when using our project management software. I've already tried restarting the computer and checking for updates, but the problem persists. Can you please assist me in diagnosing and resolving this issue? Thank you!\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model= output_model,\n",
    "    messages= [\n",
    "    { 'role': \"system\", 'content': \"You are a corporate IT support expert.\" },\n",
    "    { 'role': \"user\", 'content': user_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = \"ft:gpt-4o-mini-2024-07-18:personal::(obsecured)\"\n",
    "\n",
    "user_input = \"\"\"Hi IT support team, I'm having trouble with my work laptop running Windows 10. It frequently freezes and displays a blue screen error with the code \"SYSTEM_SERVICE_EXCEPTION.\" This issue tends to occur when I try to run multiple applications simultaneously, especially when using our project management software. I've already tried restarting the computer and checking for updates, but the problem persists. Can you please assist me in diagnosing and resolving this issue? Thank you!\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model= output_model,\n",
    "    messages= [\n",
    "    { 'role': \"system\", 'content': \"You are a corporate IT support expert.\" },\n",
    "    { 'role': \"user\", 'content': user_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = \"o3-mini-2025-01-31\"\n",
    "\n",
    "user_input = \"\"\"Hi IT support team, I'm having trouble with my work laptop running Windows 10. It frequently freezes and displays a blue screen error with the code \"SYSTEM_SERVICE_EXCEPTION.\" This issue tends to occur when I try to run multiple applications simultaneously, especially when using our project management software. I've already tried restarting the computer and checking for updates, but the problem persists. Can you please assist me in diagnosing and resolving this issue? Thank you!\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model= output_model,\n",
    "    messages= [\n",
    "    { 'role': \"system\", 'content': \"You are a corporate IT support expert.\" },\n",
    "    { 'role': \"user\", 'content': user_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Fine Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = \"ft:gpt-4o-mini-2024-07-18:personal:it-support-03-04mini:(obsecured)\"\n",
    "\n",
    "user_input = \"\"\"Hi IT support team, I'm having trouble with my work laptop running Windows 10. It frequently freezes and displays a blue screen error with the code \"SYSTEM_SERVICE_EXCEPTION.\" This issue tends to occur when I try to run multiple applications simultaneously, especially when using our project management software. I've already tried restarting the computer and checking for updates, but the problem persists. Can you please assist me in diagnosing and resolving this issue? Thank you!\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model= output_model,\n",
    "    messages= [\n",
    "    { 'role': \"system\", 'content': \"You are a corporate IT support expert.\" },\n",
    "    { 'role': \"user\", 'content': user_input}\n",
    "    ],\n",
    "    temperature=1)\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
